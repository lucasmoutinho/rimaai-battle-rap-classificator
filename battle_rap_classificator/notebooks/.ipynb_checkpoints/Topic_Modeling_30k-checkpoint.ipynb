{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import subprocess\n",
    "import multiprocessing as mp\n",
    "from subprocess import check_call\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import LinearSVC\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pyLDAvis\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "\n",
    "csv_name = '../resources/dataset/new_dataset.csv'\n",
    "csv_processed_name = \"../resources/dataset/nlp_model_2k_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede para sua amada tu tá ligado que tudo dema...</td>\n",
       "      <td>time fraco Mano Lima mano sem nenhum ataque co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano que eu sou sincero com Mc fraco que nem t...</td>\n",
       "      <td>aí Eu começo de aborto e hoje que tá morto sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>aí aí aí tá ligado é o aqui é o Ruan é cruel n...</td>\n",
       "      <td>pessoas da hora a sua visão para Mara é difíci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pode ficar tranquilo Mário sabe você acabar vo...</td>\n",
       "      <td>aí aí aí tá ligado o meu parceiro que na rima ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá ligado que você é Paulinho eu tivesse até a...</td>\n",
       "      <td>tá ligado mano que eu já chego quando detalhe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede para sua amada tu tá ligado que tudo dema...   \n",
       "1          1  mano que eu sou sincero com Mc fraco que nem t...   \n",
       "2          0  aí aí aí tá ligado é o aqui é o Ruan é cruel n...   \n",
       "3          1  pode ficar tranquilo Mário sabe você acabar vo...   \n",
       "4          1  tá ligado que você é Paulinho eu tivesse até a...   \n",
       "\n",
       "                                       Resposta_text  \n",
       "0  time fraco Mano Lima mano sem nenhum ataque co...  \n",
       "1  aí Eu começo de aborto e hoje que tá morto sai...  \n",
       "2  pessoas da hora a sua visão para Mara é difíci...  \n",
       "3  aí aí aí tá ligado o meu parceiro que na rima ...  \n",
       "4  tá ligado mano que eu já chego quando detalhe ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(csv_name)\n",
    "data[\"Ataque_text\"].fillna(\"não achado\", inplace = True) \n",
    "data[\"Resposta_text\"].fillna(\"não achado\", inplace = True)\n",
    "data['Resultado'] = data['Resultado'].apply(lambda x: 1 if x == 'ataque' else 0)\n",
    "data.drop(['Token', 'Ataque', 'Resposta', 'Round'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(row):\n",
    "    my_doc = nlp(row.Ataque_text)\n",
    "\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "   \n",
    "    filtered_sentence =[]\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word)\n",
    "    \n",
    "    row.Ataque_text = ' '.join([str(elem) for elem in filtered_sentence]) \n",
    "    \n",
    "    my_doc = nlp(row.Resposta_text)\n",
    "\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "   \n",
    "    filtered_sentence =[]\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word)\n",
    "    \n",
    "    row.Resposta_text = ' '.join([str(elem) for elem in filtered_sentence]) \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...  \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...  \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...  \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...  \n",
       "4  tá mano chego detalhe verso tá afim mano torna...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(remove_stopwords, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(row):\n",
    "    doc = nlp(row.Ataque_text)\n",
    "    \n",
    "    lemma_word1 = [] \n",
    "    for token in doc:\n",
    "        lemma_word1.append(token.lemma_)\n",
    "    lemma_word1\n",
    "    \n",
    "    row['Ataque_normalized'] = ' '.join([str(elem) for elem in lemma_word1])\n",
    "    \n",
    "    doc = nlp(row.Resposta_text)\n",
    "    \n",
    "    lemma_word1 = [] \n",
    "    for token in doc:\n",
    "        lemma_word1.append(token.lemma_)\n",
    "    lemma_word1\n",
    "    \n",
    "    row['Resposta_normalized'] = ' '.join([str(elem) for elem in lemma_word1])\n",
    "    \n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "      <th>Ataque_normalized</th>\n",
       "      <th>Resposta_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "      <td>Pede amar tá ruim melhorar chegar fito si assi...</td>\n",
       "      <td>time fraco Mano Lima manir nenhum atacar ir re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "      <td>manir sincero Mc fraco ganhar 2 o 0 tá manir c...</td>\n",
       "      <td>comedir abortar e hoje tá morto sair moleque D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "      <td>tá o o Ruan cruel imo aguentar ir quebrar teme...</td>\n",
       "      <td>pessoa horar o visão Mara difícil lidar Espero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "      <td>ficar tranquilo Mário acabar tentar tentar ir ...</td>\n",
       "      <td>tá o parceiro rimar pego mandar o dicionário t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "      <td>tá Paulinho ter arrumar o tá manir Paulinho 12...</td>\n",
       "      <td>tá manir chegar detalhar versar tá afim manir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \\\n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...   \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...   \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...   \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...   \n",
       "4  tá mano chego detalhe verso tá afim mano torna...   \n",
       "\n",
       "                                   Ataque_normalized  \\\n",
       "0  Pede amar tá ruim melhorar chegar fito si assi...   \n",
       "1  manir sincero Mc fraco ganhar 2 o 0 tá manir c...   \n",
       "2  tá o o Ruan cruel imo aguentar ir quebrar teme...   \n",
       "3  ficar tranquilo Mário acabar tentar tentar ir ...   \n",
       "4  tá Paulinho ter arrumar o tá manir Paulinho 12...   \n",
       "\n",
       "                                 Resposta_normalized  \n",
       "0  time fraco Mano Lima manir nenhum atacar ir re...  \n",
       "1  comedir abortar e hoje tá morto sair moleque D...  \n",
       "2  pessoa horar o visão Mara difícil lidar Espero...  \n",
       "3  tá o parceiro rimar pego mandar o dicionário t...  \n",
       "4  tá manir chegar detalhar versar tá afim manir ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(normalize, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semelhança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))\n",
    "\n",
    "def similaridade(row):\n",
    "    a = nlp(row.Ataque_text).vector\n",
    "    b = nlp(row.Resposta_text).vector\n",
    "    row['similaridade'] = cosine_similarity(a, b)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moutinho/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "      <th>Ataque_normalized</th>\n",
       "      <th>Resposta_normalized</th>\n",
       "      <th>similaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "      <td>Pede amar tá ruim melhorar chegar fito si assi...</td>\n",
       "      <td>time fraco Mano Lima manir nenhum atacar ir re...</td>\n",
       "      <td>0.729037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "      <td>manir sincero Mc fraco ganhar 2 o 0 tá manir c...</td>\n",
       "      <td>comedir abortar e hoje tá morto sair moleque D...</td>\n",
       "      <td>0.873968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "      <td>tá o o Ruan cruel imo aguentar ir quebrar teme...</td>\n",
       "      <td>pessoa horar o visão Mara difícil lidar Espero...</td>\n",
       "      <td>0.748563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "      <td>ficar tranquilo Mário acabar tentar tentar ir ...</td>\n",
       "      <td>tá o parceiro rimar pego mandar o dicionário t...</td>\n",
       "      <td>0.702122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "      <td>tá Paulinho ter arrumar o tá manir Paulinho 12...</td>\n",
       "      <td>tá manir chegar detalhar versar tá afim manir ...</td>\n",
       "      <td>0.853304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \\\n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...   \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...   \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...   \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...   \n",
       "4  tá mano chego detalhe verso tá afim mano torna...   \n",
       "\n",
       "                                   Ataque_normalized  \\\n",
       "0  Pede amar tá ruim melhorar chegar fito si assi...   \n",
       "1  manir sincero Mc fraco ganhar 2 o 0 tá manir c...   \n",
       "2  tá o o Ruan cruel imo aguentar ir quebrar teme...   \n",
       "3  ficar tranquilo Mário acabar tentar tentar ir ...   \n",
       "4  tá Paulinho ter arrumar o tá manir Paulinho 12...   \n",
       "\n",
       "                                 Resposta_normalized  similaridade  \n",
       "0  time fraco Mano Lima manir nenhum atacar ir re...      0.729037  \n",
       "1  comedir abortar e hoje tá morto sair moleque D...      0.873968  \n",
       "2  pessoa horar o visão Mara difícil lidar Espero...      0.748563  \n",
       "3  tá o parceiro rimar pego mandar o dicionário t...      0.702122  \n",
       "4  tá manir chegar detalhar versar tá afim manir ...      0.853304  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(similaridade, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado              0\n",
       "Ataque_text            0\n",
       "Resposta_text          0\n",
       "Ataque_normalized      0\n",
       "Resposta_normalized    0\n",
       "similaridade           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"similaridade\"].fillna(data.similaridade.mean(), inplace = True) \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ataque data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ataque_rows(row):\n",
    "    row['ataque_len'] = len(row.Ataque_text)\n",
    "    txt = row.Ataque_text\n",
    "    row['ataque_ao'] = len(re.findall(\"ão \", txt)) + len(re.findall(\"ão$\", txt))\n",
    "    row['ataque_ado'] = len(re.findall(\"ado \", txt)) + len(re.findall(\"ado$\", txt))\n",
    "    row['ataque_ade'] = len(re.findall(\"ade \", txt)) + len(re.findall(\"ade$\", txt))\n",
    "    row['ataque_em'] = len(re.findall(\"em \", txt)) + len(re.findall(\"em$\", txt))\n",
    "    row['ataque_in'] = len(re.findall(\"in \", txt)) + len(re.findall(\"in$\", txt))\n",
    "    row['ataque_ar'] = len(re.findall(\"ar \", txt)) + len(re.findall(\"ar$\", txt))\n",
    "    row['ataque_er'] = len(re.findall(\"er \", txt)) + len(re.findall(\"er$\", txt))\n",
    "    row['ataque_or'] = len(re.findall(\"or \", txt)) + len(re.findall(\"or$\", txt))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "      <th>Ataque_normalized</th>\n",
       "      <th>Resposta_normalized</th>\n",
       "      <th>similaridade</th>\n",
       "      <th>ataque_len</th>\n",
       "      <th>ataque_ao</th>\n",
       "      <th>ataque_ado</th>\n",
       "      <th>ataque_ade</th>\n",
       "      <th>ataque_em</th>\n",
       "      <th>ataque_in</th>\n",
       "      <th>ataque_ar</th>\n",
       "      <th>ataque_er</th>\n",
       "      <th>ataque_or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "      <td>Pede amar tá ruim melhorar chegar fito si assi...</td>\n",
       "      <td>time fraco Mano Lima manir nenhum atacar ir re...</td>\n",
       "      <td>0.729037</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "      <td>manir sincero Mc fraco ganhar 2 o 0 tá manir c...</td>\n",
       "      <td>comedir abortar e hoje tá morto sair moleque D...</td>\n",
       "      <td>0.873968</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "      <td>tá o o Ruan cruel imo aguentar ir quebrar teme...</td>\n",
       "      <td>pessoa horar o visão Mara difícil lidar Espero...</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "      <td>ficar tranquilo Mário acabar tentar tentar ir ...</td>\n",
       "      <td>tá o parceiro rimar pego mandar o dicionário t...</td>\n",
       "      <td>0.702122</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "      <td>tá Paulinho ter arrumar o tá manir Paulinho 12...</td>\n",
       "      <td>tá manir chegar detalhar versar tá afim manir ...</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \\\n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...   \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...   \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...   \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...   \n",
       "4  tá mano chego detalhe verso tá afim mano torna...   \n",
       "\n",
       "                                   Ataque_normalized  \\\n",
       "0  Pede amar tá ruim melhorar chegar fito si assi...   \n",
       "1  manir sincero Mc fraco ganhar 2 o 0 tá manir c...   \n",
       "2  tá o o Ruan cruel imo aguentar ir quebrar teme...   \n",
       "3  ficar tranquilo Mário acabar tentar tentar ir ...   \n",
       "4  tá Paulinho ter arrumar o tá manir Paulinho 12...   \n",
       "\n",
       "                                 Resposta_normalized  similaridade  \\\n",
       "0  time fraco Mano Lima manir nenhum atacar ir re...      0.729037   \n",
       "1  comedir abortar e hoje tá morto sair moleque D...      0.873968   \n",
       "2  pessoa horar o visão Mara difícil lidar Espero...      0.748563   \n",
       "3  tá o parceiro rimar pego mandar o dicionário t...      0.702122   \n",
       "4  tá manir chegar detalhar versar tá afim manir ...      0.853304   \n",
       "\n",
       "   ataque_len  ataque_ao  ataque_ado  ataque_ade  ataque_em  ataque_in  \\\n",
       "0         190          1           1           0          0          0   \n",
       "1         210          0           0           0          0          0   \n",
       "2         152          1           0           0          0          0   \n",
       "3         176          0           0           0          0          0   \n",
       "4         230          0           2           0          0          0   \n",
       "\n",
       "   ataque_ar  ataque_er  ataque_or  \n",
       "0          1          0          0  \n",
       "1          1          0          0  \n",
       "2          1          0          0  \n",
       "3          3          0          0  \n",
       "4          0          0          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(ataque_rows, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ataque_rows(row):\n",
    "    row['resposta_len'] = len(row.Resposta_text)\n",
    "    txt = row.Resposta_text\n",
    "    row['resposta_ao'] = len(re.findall(\"ão \", txt)) + len(re.findall(\"ão$\", txt))\n",
    "    row['resposta_ado'] = len(re.findall(\"ado \", txt)) + len(re.findall(\"ado$\", txt))\n",
    "    row['resposta_ade'] = len(re.findall(\"ade \", txt)) + len(re.findall(\"ade$\", txt))\n",
    "    row['resposta_em'] = len(re.findall(\"em \", txt)) + len(re.findall(\"em$\", txt))\n",
    "    row['resposta_in'] = len(re.findall(\"in \", txt)) + len(re.findall(\"in$\", txt))\n",
    "    row['resposta_ar'] = len(re.findall(\"ar \", txt)) + len(re.findall(\"ar$\", txt))\n",
    "    row['resposta_er'] = len(re.findall(\"er \", txt)) + len(re.findall(\"er$\", txt))\n",
    "    row['resposta_or'] = len(re.findall(\"or \", txt)) + len(re.findall(\"or$\", txt))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "      <th>Ataque_normalized</th>\n",
       "      <th>Resposta_normalized</th>\n",
       "      <th>similaridade</th>\n",
       "      <th>ataque_len</th>\n",
       "      <th>ataque_ao</th>\n",
       "      <th>ataque_ado</th>\n",
       "      <th>ataque_ade</th>\n",
       "      <th>...</th>\n",
       "      <th>ataque_or</th>\n",
       "      <th>resposta_len</th>\n",
       "      <th>resposta_ao</th>\n",
       "      <th>resposta_ado</th>\n",
       "      <th>resposta_ade</th>\n",
       "      <th>resposta_em</th>\n",
       "      <th>resposta_in</th>\n",
       "      <th>resposta_ar</th>\n",
       "      <th>resposta_er</th>\n",
       "      <th>resposta_or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "      <td>Pede amar tá ruim melhorar chegar fito si assi...</td>\n",
       "      <td>time fraco Mano Lima manir nenhum atacar ir re...</td>\n",
       "      <td>0.729037</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "      <td>manir sincero Mc fraco ganhar 2 o 0 tá manir c...</td>\n",
       "      <td>comedir abortar e hoje tá morto sair moleque D...</td>\n",
       "      <td>0.873968</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "      <td>tá o o Ruan cruel imo aguentar ir quebrar teme...</td>\n",
       "      <td>pessoa horar o visão Mara difícil lidar Espero...</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "      <td>ficar tranquilo Mário acabar tentar tentar ir ...</td>\n",
       "      <td>tá o parceiro rimar pego mandar o dicionário t...</td>\n",
       "      <td>0.702122</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "      <td>tá Paulinho ter arrumar o tá manir Paulinho 12...</td>\n",
       "      <td>tá manir chegar detalhar versar tá afim manir ...</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \\\n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...   \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...   \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...   \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...   \n",
       "4  tá mano chego detalhe verso tá afim mano torna...   \n",
       "\n",
       "                                   Ataque_normalized  \\\n",
       "0  Pede amar tá ruim melhorar chegar fito si assi...   \n",
       "1  manir sincero Mc fraco ganhar 2 o 0 tá manir c...   \n",
       "2  tá o o Ruan cruel imo aguentar ir quebrar teme...   \n",
       "3  ficar tranquilo Mário acabar tentar tentar ir ...   \n",
       "4  tá Paulinho ter arrumar o tá manir Paulinho 12...   \n",
       "\n",
       "                                 Resposta_normalized  similaridade  \\\n",
       "0  time fraco Mano Lima manir nenhum atacar ir re...      0.729037   \n",
       "1  comedir abortar e hoje tá morto sair moleque D...      0.873968   \n",
       "2  pessoa horar o visão Mara difícil lidar Espero...      0.748563   \n",
       "3  tá o parceiro rimar pego mandar o dicionário t...      0.702122   \n",
       "4  tá manir chegar detalhar versar tá afim manir ...      0.853304   \n",
       "\n",
       "   ataque_len  ataque_ao  ataque_ado  ataque_ade  ...  ataque_or  \\\n",
       "0         190          1           1           0  ...          0   \n",
       "1         210          0           0           0  ...          0   \n",
       "2         152          1           0           0  ...          0   \n",
       "3         176          0           0           0  ...          0   \n",
       "4         230          0           2           0  ...          0   \n",
       "\n",
       "   resposta_len  resposta_ao  resposta_ado  resposta_ade  resposta_em  \\\n",
       "0           267            1             0             0            0   \n",
       "1           268            0             0             0            0   \n",
       "2           178            1             0             0            0   \n",
       "3           213            0             0             0            0   \n",
       "4           144            0             0             0            0   \n",
       "\n",
       "   resposta_in  resposta_ar  resposta_er  resposta_or  \n",
       "0            0            0            0            0  \n",
       "1            0            1            0            1  \n",
       "2            0            8            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(ataque_rows, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(csv_processed_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "y = data.Resultado.copy()\n",
    "X.drop(['Resultado'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipes():\n",
    "    ataque_vectors_train = np.array([nlp(text).vector for text in X_train.Ataque_normalized])\n",
    "    ataque_vectors_test = np.array([nlp(text).vector for text in X_test.Ataque_normalized])\n",
    "    resposta_vectors_train = np.array([nlp(text).vector for text in X_train.Resposta_normalized])\n",
    "    resposta_vectors_test = np.array([nlp(text).vector for text in X_test.Resposta_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino:  0.18231773143309093\n",
      "teste:  0.4847236065526045\n"
     ]
    }
   ],
   "source": [
    "model_ataque = RandomForestRegressor(random_state=1)\n",
    "# Fit the model\n",
    "model_ataque.fit(ataque_vectors_train,y_train)\n",
    "\n",
    "model_ataque_preds_traine = model_ataque.predict(ataque_vectors_train)\n",
    "model_ataque_preds = model_ataque.predict(ataque_vectors_test)\n",
    "print('treino: ', mean_absolute_error(y_train, model_ataque_preds_traine))\n",
    "print('teste: ', mean_absolute_error(y_test, model_ataque_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino:  0.17886750874374968\n",
      "teste:  0.47468614585294766\n"
     ]
    }
   ],
   "source": [
    "model_resposta = RandomForestRegressor(random_state=1)\n",
    "# Fit the model\n",
    "model_resposta.fit(resposta_vectors_train,y_train)\n",
    "\n",
    "model_resposta_preds_train = model_resposta.predict(resposta_vectors_train)\n",
    "model_resposta_preds = model_resposta.predict(resposta_vectors_test)\n",
    "print('treino: ', mean_absolute_error(y_train, model_resposta_preds_train))\n",
    "print('teste: ', mean_absolute_error(y_test, model_resposta_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similaridade</th>\n",
       "      <th>ataque_len</th>\n",
       "      <th>ataque_ao</th>\n",
       "      <th>ataque_ado</th>\n",
       "      <th>ataque_ade</th>\n",
       "      <th>ataque_em</th>\n",
       "      <th>ataque_in</th>\n",
       "      <th>ataque_ar</th>\n",
       "      <th>ataque_er</th>\n",
       "      <th>ataque_or</th>\n",
       "      <th>resposta_len</th>\n",
       "      <th>resposta_ao</th>\n",
       "      <th>resposta_ado</th>\n",
       "      <th>resposta_ade</th>\n",
       "      <th>resposta_em</th>\n",
       "      <th>resposta_in</th>\n",
       "      <th>resposta_ar</th>\n",
       "      <th>resposta_er</th>\n",
       "      <th>resposta_or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>0.701008</td>\n",
       "      <td>292</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14434</th>\n",
       "      <td>0.884509</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11423</th>\n",
       "      <td>0.676540</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>0.699633</td>\n",
       "      <td>286</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>0.906294</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       similaridade  ataque_len  ataque_ao  ataque_ado  ataque_ade  ataque_em  \\\n",
       "7077       0.701008         292          2           3           0          0   \n",
       "14434      0.884509         248          1           1           0          0   \n",
       "11423      0.676540         241          1           0           0          0   \n",
       "14868      0.699633         286          5           1           0          1   \n",
       "4429       0.906294         235          1           2           0          0   \n",
       "\n",
       "       ataque_in  ataque_ar  ataque_er  ataque_or  resposta_len  resposta_ao  \\\n",
       "7077           0          4          0          0           299            1   \n",
       "14434          0          2          0          0           238            3   \n",
       "11423          0          1          0          0           194            2   \n",
       "14868          0          1          0          0           284            1   \n",
       "4429           0          1          1          0           201            2   \n",
       "\n",
       "       resposta_ado  resposta_ade  resposta_em  resposta_in  resposta_ar  \\\n",
       "7077              1             2            0            0            3   \n",
       "14434             1             0            0            0            4   \n",
       "11423             2             0            0            1            5   \n",
       "14868             0             0            0            0            6   \n",
       "4429              0             0            0            0            3   \n",
       "\n",
       "       resposta_er  resposta_or  \n",
       "7077             0            0  \n",
       "14434            1            1  \n",
       "11423            0            0  \n",
       "14868            1            0  \n",
       "4429             2            1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.copy()\n",
    "X.drop(['Ataque_text', 'Resposta_text', 'Ataque_normalized', 'Resposta_normalized'], axis=1, inplace=True)\n",
    "y = data.Resultado.copy()\n",
    "X.drop(['Resultado'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino:  99.99605070889776\n",
      "teste:  60.227452219238664\n"
     ]
    }
   ],
   "source": [
    "model_table = RandomForestRegressor(random_state=1, n_estimators= 80)\n",
    "# Fit the model\n",
    "model_table.fit(X_train,y_train)\n",
    "\n",
    "model_table_preds_train = model_table.predict(X_train)\n",
    "model_table_preds = model_table.predict(X_test)\n",
    "print('treino: ', (1 - mean_absolute_error(y_train, np.round(model_table_preds_train, 0))) * 100)\n",
    "print('teste: ', (1 - mean_absolute_error(y_test, np.round(model_table_preds, 0))) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino:  68.8479917854745\n",
      "teste:  62.233454430579684\n"
     ]
    }
   ],
   "source": [
    "model_table = XGBRegressor(n_estimators=30)\n",
    "# Fit the model\n",
    "model_table.fit(X_train,y_train)\n",
    "\n",
    "model_table_preds_train = model_table.predict(X_train)\n",
    "model_table_preds = model_table.predict(X_test)\n",
    "print('treino: ', (1 - mean_absolute_error(y_train, np.round(model_table_preds_train, 0))) * 100)\n",
    "print('teste: ', (1 - mean_absolute_error(y_test, np.round(model_table_preds, 0))) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Ataque_text</th>\n",
       "      <th>Resposta_text</th>\n",
       "      <th>Ataque_normalized</th>\n",
       "      <th>Resposta_normalized</th>\n",
       "      <th>similaridade</th>\n",
       "      <th>ataque_len</th>\n",
       "      <th>ataque_ao</th>\n",
       "      <th>ataque_ado</th>\n",
       "      <th>ataque_ade</th>\n",
       "      <th>...</th>\n",
       "      <th>ataque_or</th>\n",
       "      <th>resposta_len</th>\n",
       "      <th>resposta_ao</th>\n",
       "      <th>resposta_ado</th>\n",
       "      <th>resposta_ade</th>\n",
       "      <th>resposta_em</th>\n",
       "      <th>resposta_in</th>\n",
       "      <th>resposta_ar</th>\n",
       "      <th>resposta_er</th>\n",
       "      <th>resposta_or</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pede amada tá ruim melhorar chego fita si assi...</td>\n",
       "      <td>time fraco Mano Lima mano nenhum ataque vou re...</td>\n",
       "      <td>Pede amar tá ruim melhorar chegar fito si assi...</td>\n",
       "      <td>time fraco Mano Lima manir nenhum atacar ir re...</td>\n",
       "      <td>0.729037</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mano sincero Mc fraco ganho 2 a 0 tá mano comu...</td>\n",
       "      <td>começo aborto e hoje tá morto sai moleque Deix...</td>\n",
       "      <td>manir sincero Mc fraco ganhar 2 o 0 tá manir c...</td>\n",
       "      <td>comedir abortar e hoje tá morto sair moleque D...</td>\n",
       "      <td>0.873968</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tá o o Ruan cruel ima aguenta vou quebrando te...</td>\n",
       "      <td>pessoas hora a visão Mara difícil lidar Espero...</td>\n",
       "      <td>tá o o Ruan cruel imo aguentar ir quebrar teme...</td>\n",
       "      <td>pessoa horar o visão Mara difícil lidar Espero...</td>\n",
       "      <td>0.748563</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ficar tranquilo Mário acabar tenta tenta vou b...</td>\n",
       "      <td>tá o parceiro rima pega mandou o dicionário tr...</td>\n",
       "      <td>ficar tranquilo Mário acabar tentar tentar ir ...</td>\n",
       "      <td>tá o parceiro rimar pego mandar o dicionário t...</td>\n",
       "      <td>0.702122</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tá Paulinho tivesse arrumando o tá mano Paulin...</td>\n",
       "      <td>tá mano chego detalhe verso tá afim mano torna...</td>\n",
       "      <td>tá Paulinho ter arrumar o tá manir Paulinho 12...</td>\n",
       "      <td>tá manir chegar detalhar versar tá afim manir ...</td>\n",
       "      <td>0.853304</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resultado                                        Ataque_text  \\\n",
       "0          0  Pede amada tá ruim melhorar chego fita si assi...   \n",
       "1          1  mano sincero Mc fraco ganho 2 a 0 tá mano comu...   \n",
       "2          0  tá o o Ruan cruel ima aguenta vou quebrando te...   \n",
       "3          1  ficar tranquilo Mário acabar tenta tenta vou b...   \n",
       "4          1  tá Paulinho tivesse arrumando o tá mano Paulin...   \n",
       "\n",
       "                                       Resposta_text  \\\n",
       "0  time fraco Mano Lima mano nenhum ataque vou re...   \n",
       "1  começo aborto e hoje tá morto sai moleque Deix...   \n",
       "2  pessoas hora a visão Mara difícil lidar Espero...   \n",
       "3  tá o parceiro rima pega mandou o dicionário tr...   \n",
       "4  tá mano chego detalhe verso tá afim mano torna...   \n",
       "\n",
       "                                   Ataque_normalized  \\\n",
       "0  Pede amar tá ruim melhorar chegar fito si assi...   \n",
       "1  manir sincero Mc fraco ganhar 2 o 0 tá manir c...   \n",
       "2  tá o o Ruan cruel imo aguentar ir quebrar teme...   \n",
       "3  ficar tranquilo Mário acabar tentar tentar ir ...   \n",
       "4  tá Paulinho ter arrumar o tá manir Paulinho 12...   \n",
       "\n",
       "                                 Resposta_normalized  similaridade  \\\n",
       "0  time fraco Mano Lima manir nenhum atacar ir re...      0.729037   \n",
       "1  comedir abortar e hoje tá morto sair moleque D...      0.873968   \n",
       "2  pessoa horar o visão Mara difícil lidar Espero...      0.748563   \n",
       "3  tá o parceiro rimar pego mandar o dicionário t...      0.702122   \n",
       "4  tá manir chegar detalhar versar tá afim manir ...      0.853304   \n",
       "\n",
       "   ataque_len  ataque_ao  ataque_ado  ataque_ade  ...  ataque_or  \\\n",
       "0         190          1           1           0  ...          0   \n",
       "1         210          0           0           0  ...          0   \n",
       "2         152          1           0           0  ...          0   \n",
       "3         176          0           0           0  ...          0   \n",
       "4         230          0           2           0  ...          0   \n",
       "\n",
       "   resposta_len  resposta_ao  resposta_ado  resposta_ade  resposta_em  \\\n",
       "0           267            1             0             0            0   \n",
       "1           268            0             0             0            0   \n",
       "2           178            1             0             0            0   \n",
       "3           213            0             0             0            0   \n",
       "4           144            0             0             0            0   \n",
       "\n",
       "   resposta_in  resposta_ar  resposta_er  resposta_or  \n",
       "0            0            0            0            0  \n",
       "1            0            1            0            1  \n",
       "2            0            8            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_df = pd.read_csv(csv_processed_name, index_col=0)\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer generates weights relative to how many times a word or a combination or words(ngrams) appear no matter how big is the document. While TfidfTransformer makes it proportional to the size of the document. The parm \"use_idf\" highlights the less frequents ones because they can be more informative than other words that appear a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "''' Best parameter using GridSearch (CV score=0.535): \n",
    "{'clf__alpha': 1e-05, 'clf__max_iter': 80, 'clf__penalty': 'l2', 'tfidf__norm': 'l1',\n",
    "'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True,\n",
    "'vect__max_df': 0.6000000000000001, 'vect__max_features': None, 'vect__min_df': 0.0007,\n",
    "'vect__ngram_range': (1, 2)}\n",
    "Those were obtained on the next code block.\n",
    "'''\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "''' Let's transform the lemmatized documents into count vectors '''\n",
    "count_vectors_ataque = count_vectorizer.fit_transform(\n",
    "    processed_data_df['Ataque_normalized'].values.astype('U'))\n",
    "count_vectors_resposta = count_vectorizer.fit_transform(\n",
    "    processed_data_df['Resposta_normalized'].values.astype('U'))\n",
    "\n",
    "''' Then use those count vectors to generate frequency vectors '''\n",
    "frequency_vectors_ataque = tfidf_transformer.fit_transform(count_vectors_ataque)\n",
    "frequency_vectors_resposta = tfidf_transformer.fit_transform(count_vectors_resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizando termos ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Feature Code</th>\n",
       "      <th>Feature Percentual Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alanis</td>\n",
       "      <td>910</td>\n",
       "      <td>14.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amiga</td>\n",
       "      <td>1237</td>\n",
       "      <td>13.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ativar</td>\n",
       "      <td>1993</td>\n",
       "      <td>15.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auroch</td>\n",
       "      <td>2098</td>\n",
       "      <td>27.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bergman</td>\n",
       "      <td>2727</td>\n",
       "      <td>29.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>canários</td>\n",
       "      <td>3982</td>\n",
       "      <td>29.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chutou</td>\n",
       "      <td>4823</td>\n",
       "      <td>5.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>degradar</td>\n",
       "      <td>6584</td>\n",
       "      <td>9.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>famosinha</td>\n",
       "      <td>9275</td>\n",
       "      <td>24.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>formato</td>\n",
       "      <td>9883</td>\n",
       "      <td>12.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jataí</td>\n",
       "      <td>12399</td>\n",
       "      <td>8.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jenny</td>\n",
       "      <td>12444</td>\n",
       "      <td>26.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mcds</td>\n",
       "      <td>14553</td>\n",
       "      <td>17.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mercury</td>\n",
       "      <td>14750</td>\n",
       "      <td>27.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>milharal</td>\n",
       "      <td>14919</td>\n",
       "      <td>16.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>moradores</td>\n",
       "      <td>15212</td>\n",
       "      <td>8.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>percalço</td>\n",
       "      <td>17173</td>\n",
       "      <td>25.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>petit</td>\n",
       "      <td>17349</td>\n",
       "      <td>24.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pi</td>\n",
       "      <td>17393</td>\n",
       "      <td>9.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pretos</td>\n",
       "      <td>18175</td>\n",
       "      <td>25.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>publicação</td>\n",
       "      <td>18484</td>\n",
       "      <td>20.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>science</td>\n",
       "      <td>20489</td>\n",
       "      <td>11.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sorrizinho</td>\n",
       "      <td>21262</td>\n",
       "      <td>21.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>superpotência</td>\n",
       "      <td>21544</td>\n",
       "      <td>16.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sônico</td>\n",
       "      <td>21688</td>\n",
       "      <td>22.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vertinho</td>\n",
       "      <td>23398</td>\n",
       "      <td>7.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>viadão</td>\n",
       "      <td>23432</td>\n",
       "      <td>5.88%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature Name  Feature Code Feature Percentual Frequency\n",
       "0          alanis           910                       14.47%\n",
       "1           amiga          1237                       13.66%\n",
       "2          ativar          1993                       15.38%\n",
       "3          auroch          2098                        27.3%\n",
       "4         bergman          2727                        29.2%\n",
       "5        canários          3982                        29.2%\n",
       "6          chutou          4823                        5.53%\n",
       "7        degradar          6584                        9.43%\n",
       "8       famosinha          9275                       24.99%\n",
       "9         formato          9883                       12.78%\n",
       "10          jataí         12399                         8.3%\n",
       "11          jenny         12444                       26.19%\n",
       "12           mcds         14553                       17.09%\n",
       "13        mercury         14750                        27.3%\n",
       "14       milharal         14919                       16.78%\n",
       "15      moradores         15212                        8.19%\n",
       "16       percalço         17173                       25.77%\n",
       "17          petit         17349                       24.07%\n",
       "18             pi         17393                        9.71%\n",
       "19         pretos         18175                        25.4%\n",
       "20     publicação         18484                        20.5%\n",
       "21        science         20489                       11.39%\n",
       "22     sorrizinho         21262                        21.7%\n",
       "23  superpotência         21544                       16.59%\n",
       "24         sônico         21688                        22.4%\n",
       "25       vertinho         23398                        7.42%\n",
       "26         viadão         23432                        5.88%"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_codes_ataque = []\n",
    "for code, value in enumerate(count_vectors_ataque.toarray()[0]):\n",
    "    if value:\n",
    "        term_codes_ataque.append(code)\n",
    "\n",
    "frequency_values_ataque = []\n",
    "for code, value in enumerate(frequency_vectors_ataque.toarray()[0]):\n",
    "    if code in term_codes_ataque:\n",
    "        frequency_values_ataque.append(str(round(value*100, 2))+\"%\")\n",
    "\n",
    "terms_ataque = []\n",
    "for code in term_codes_ataque:\n",
    "    terms_ataque.append(count_vectorizer.get_feature_names()[code])\n",
    "\n",
    "features_frequencies_df_ataque = pd.DataFrame({'Feature Name': terms_ataque, 'Feature Code': term_codes_ataque, 'Feature Percentual Frequency': frequency_values_ataque})\n",
    "features_frequencies_df_ataque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos as partes de grindsearching em seguida são hiperparametrizações - não precisa ser feito mais de uma vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gridsearching = False\n",
    "if is_gridsearching:\n",
    "    search_count_vectorizer = CountVectorizer()\n",
    "    search_tfidf_transformer = TfidfTransformer()\n",
    "    clf = SGDClassifier(alpha=1e-05, max_iter=80, penalty='l2')\n",
    "    \n",
    "    ''' Those are all the params values that will be tested.'''\n",
    "    search_params = {\n",
    "        'vect__min_df': np.arange(0, 0.001, 0.0003),\n",
    "        'vect__max_df': np.arange(0.2, 0.9, 0.3),\n",
    "        'vect__max_features': [None],\n",
    "        'vect__ngram_range': [(1, 2), (1, 3), (2, 3)],\n",
    "        'tfidf__norm': ['l2'],\n",
    "        'tfidf__use_idf': [False, True],\n",
    "        'tfidf__smooth_idf': [False],\n",
    "        'tfidf__sublinear_tf' : [False, True]}\n",
    "    \n",
    "    search_pipeline = Pipeline([\n",
    "        ('vect', search_count_vectorizer),\n",
    "        ('tfidf', search_tfidf_transformer),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(search_pipeline,\n",
    "                      param_grid=search_params, cv=5)\n",
    "    gs.fit(processed_data_df['Ataque_normalized'].values.astype('U'), processed_data_df['Resultado'])\n",
    "    results = gs.cv_results_\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizando termos defesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Feature Code</th>\n",
       "      <th>Feature Percentual Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atacar</td>\n",
       "      <td>1946</td>\n",
       "      <td>9.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bagulho</td>\n",
       "      <td>2319</td>\n",
       "      <td>19.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camarada</td>\n",
       "      <td>3827</td>\n",
       "      <td>30.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>causar</td>\n",
       "      <td>4342</td>\n",
       "      <td>13.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chegar</td>\n",
       "      <td>4671</td>\n",
       "      <td>18.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>complicar</td>\n",
       "      <td>5359</td>\n",
       "      <td>18.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>destreza</td>\n",
       "      <td>7097</td>\n",
       "      <td>23.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fraco</td>\n",
       "      <td>9948</td>\n",
       "      <td>8.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frank</td>\n",
       "      <td>9985</td>\n",
       "      <td>24.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gatilho</td>\n",
       "      <td>10403</td>\n",
       "      <td>20.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hoje</td>\n",
       "      <td>11291</td>\n",
       "      <td>8.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ir</td>\n",
       "      <td>12161</td>\n",
       "      <td>4.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lima</td>\n",
       "      <td>13369</td>\n",
       "      <td>19.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>limpeza</td>\n",
       "      <td>13387</td>\n",
       "      <td>24.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lipe</td>\n",
       "      <td>13429</td>\n",
       "      <td>28.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mandar</td>\n",
       "      <td>14100</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>manir</td>\n",
       "      <td>14163</td>\n",
       "      <td>7.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mano</td>\n",
       "      <td>14170</td>\n",
       "      <td>22.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mc</td>\n",
       "      <td>14538</td>\n",
       "      <td>16.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mentir</td>\n",
       "      <td>14730</td>\n",
       "      <td>10.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>morte</td>\n",
       "      <td>15265</td>\n",
       "      <td>14.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nenhum</td>\n",
       "      <td>15761</td>\n",
       "      <td>14.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pego</td>\n",
       "      <td>17063</td>\n",
       "      <td>10.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pião</td>\n",
       "      <td>17650</td>\n",
       "      <td>24.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>responder</td>\n",
       "      <td>19601</td>\n",
       "      <td>11.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sujo</td>\n",
       "      <td>21504</td>\n",
       "      <td>22.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>suportar</td>\n",
       "      <td>21561</td>\n",
       "      <td>15.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sério</td>\n",
       "      <td>21667</td>\n",
       "      <td>13.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>time</td>\n",
       "      <td>22233</td>\n",
       "      <td>17.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>trocado</td>\n",
       "      <td>22750</td>\n",
       "      <td>23.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tá</td>\n",
       "      <td>22916</td>\n",
       "      <td>7.54%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Name  Feature Code Feature Percentual Frequency\n",
       "0        atacar          1946                        9.62%\n",
       "1       bagulho          2319                       19.44%\n",
       "2      camarada          3827                       30.18%\n",
       "3        causar          4342                        13.1%\n",
       "4        chegar          4671                       18.45%\n",
       "5     complicar          5359                       18.51%\n",
       "6      destreza          7097                       23.76%\n",
       "7         fraco          9948                        8.62%\n",
       "8         frank          9985                       24.36%\n",
       "9       gatilho         10403                       20.96%\n",
       "10         hoje         11291                        8.26%\n",
       "11           ir         12161                        4.33%\n",
       "12         lima         13369                        19.7%\n",
       "13      limpeza         13387                       24.92%\n",
       "14         lipe         13429                        28.5%\n",
       "15       mandar         14100                        10.7%\n",
       "16        manir         14163                        7.99%\n",
       "17         mano         14170                       22.54%\n",
       "18           mc         14538                       16.93%\n",
       "19       mentir         14730                       10.34%\n",
       "20        morte         15265                       14.62%\n",
       "21       nenhum         15761                       14.47%\n",
       "22         pego         17063                       10.21%\n",
       "23         pião         17650                       24.72%\n",
       "24    responder         19601                       11.68%\n",
       "25         sujo         21504                       22.84%\n",
       "26     suportar         21561                        15.1%\n",
       "27        sério         21667                       13.68%\n",
       "28         time         22233                       17.14%\n",
       "29      trocado         22750                       23.26%\n",
       "30           tá         22916                        7.54%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_codes_resposta = []\n",
    "for code, value in enumerate(count_vectors_resposta.toarray()[0]):\n",
    "    if value:\n",
    "        term_codes_resposta.append(code)\n",
    "\n",
    "frequency_values_resposta = []\n",
    "for code, value in enumerate(frequency_vectors_resposta.toarray()[0]):\n",
    "    if code in term_codes_resposta:\n",
    "        frequency_values_resposta.append(str(round(value*100, 2))+\"%\")\n",
    "\n",
    "terms_resposta = []\n",
    "for code in term_codes_resposta:\n",
    "    terms_resposta.append(count_vectorizer.get_feature_names()[code])\n",
    "\n",
    "features_frequencies_df_resposta = pd.DataFrame({'Feature Name': terms_resposta, 'Feature Code': term_codes_resposta, 'Feature Percentual Frequency': frequency_values_resposta})\n",
    "features_frequencies_df_resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gridsearching = False\n",
    "if is_gridsearching:\n",
    "    search_count_vectorizer = CountVectorizer()\n",
    "    search_tfidf_transformer = TfidfTransformer()\n",
    "    clf = SGDClassifier(alpha=1e-05, max_iter=80, penalty='l2')\n",
    "    \n",
    "    ''' Those are all the params values that will be tested.'''\n",
    "    search_params = {\n",
    "        'vect__min_df': np.arange(0, 0.001, 0.0003),\n",
    "        'vect__max_df': np.arange(0.2, 0.9, 0.3),\n",
    "        'vect__max_features': [None],\n",
    "        'vect__ngram_range': [(1, 2), (1, 3), (2, 3)],\n",
    "        'tfidf__norm': ['l2'],\n",
    "        'tfidf__use_idf': [False, True],\n",
    "        'tfidf__smooth_idf': [False],\n",
    "        'tfidf__sublinear_tf' : [False, True]}\n",
    "    \n",
    "    search_pipeline = Pipeline([\n",
    "        ('vect', search_count_vectorizer),\n",
    "        ('tfidf', search_tfidf_transformer),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV(search_pipeline,\n",
    "                      param_grid=search_params, cv=5)\n",
    "    gs.fit(processed_data_df['Resposta_normalized'].values.astype('U'), processed_data_df['Resultado'])\n",
    "    results = gs.cv_results_\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics ataque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating and fit the LDA model using the count_vectors generated before '''\n",
    "lda_ataque = LDA(n_jobs=-1)\n",
    "topics_vectors = lda_ataque.fit_transform(count_vectors_ataque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
